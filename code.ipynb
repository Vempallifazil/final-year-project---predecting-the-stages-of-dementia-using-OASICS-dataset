# Import Libraries
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import os
# Load and preprocess the data
train_dir = "train"
val_dir = "test"
# Data augmentation for training set
datagen_train = ImageDataGenerator(rescale=1.0/255, rotation_range=20, width_shift_range=0.2, 
                                   height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, 
                                   horizontal_flip=True, fill_mode='nearest')

datagen_val = ImageDataGenerator(rescale=1.0/255)

train_data = datagen_train.flow_from_directory(train_dir, target_size=(150, 150), batch_size=32, 
                                               class_mode='categorical')
val_data = datagen_val.flow_from_directory(val_dir, target_size=(150, 150), batch_size=32, 
                                           class_mode='categorical', shuffle=False)

# Build the CNN model
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D((2, 2)),
    
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(4, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
epochs = 20
history = model.fit(train_data, validation_data=val_data, epochs=epochs)

# Save the model
model.save("cnn_model.h5")
# Plot accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training and Validation Accuracy')
plt.show()

# Evaluate the model and plot confusion matrix
y_pred = model.predict(val_data)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = val_data.classes

# Confusion Matrix
conf_mat = confusion_matrix(y_true, y_pred_classes)
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()
# Classification Report
print("Classification Report:\n")
print(classification_report(y_true, y_pred_classes))

## MobileNet Model
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import os

# Load and preprocess the data
train_dir = "train"
val_dir = "test"


# Data augmentation for training set
datagen_train = ImageDataGenerator(rescale=1.0/255, rotation_range=20, width_shift_range=0.1, 
                                   height_shift_range=0.1, shear_range=0.1, zoom_range=0.1, 
                                   horizontal_flip=True, fill_mode='nearest')

datagen_val = ImageDataGenerator(rescale=1.0/255)

train_data = datagen_train.flow_from_directory(train_dir, target_size=(224, 224), batch_size=32, 
                                               class_mode='categorical', color_mode='grayscale')
val_data = datagen_val.flow_from_directory(val_dir, target_size=(224, 224), batch_size=32, 
                                           class_mode='categorical', color_mode='grayscale', shuffle=False)

# Load the MobileNetV2 model
base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')
base_model.trainable = False

# Adjust the input for grayscale images by adding a Conv2D layer to expand channel to 3
input_layer = tf.keras.layers.Input(shape=(224, 224, 1))
x = tf.keras.layers.Conv2D(3, (3, 3), padding='same', activation='relu')(input_layer)
x = base_model(x, training=False)

# Build the rest of the model
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(128, activation='relu')(x)
x = tf.keras.layers.Dropout(0.5)(x)
output_layer = tf.keras.layers.Dense(4, activation='softmax')(x)

model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
epochs = 20
history = model.fit(train_data, validation_data=val_data, epochs=epochs)

# Save the model
model.save("mobilenet_model.h5")
# Plot accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training and Validation Accuracy')
plt.show()

# Evaluate the model and plot confusion matrix
y_pred = model.predict(val_data)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = val_data.classes
# Confusion Matrix
conf_mat = confusion_matrix(y_true, y_pred_classes)
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()
# Classification Report
print("Classification Report:\n")
print(classification_report(y_true, y_pred_classes))

import tensorflow as tf
from tensorflow.keras.preprocessing import image
import numpy as np

# Define class labels based on your training
class_labels = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']

# Load the saved model
model = tf.keras.models.load_model("mobilenet_model.h5")

# Function to preprocess image and make prediction
def predict_class(image_path):
    # Load the image, resize it to 224x224 (the target size used in training)
    img = image.load_img(image_path, target_size=(224, 224), color_mode='grayscale')
    
    # Convert the image to a numpy array and expand dimensions (for batch size of 1)
    img_array = image.img_to_array(img)  # Convert image to numpy array
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    
    # Normalize the image
    img_array /= 255.0  # Same normalization as during training
    
    # Predict using the model
    predictions = model.predict(img_array)
    
    # Get the class index with the highest probability
    predicted_class_idx = np.argmax(predictions, axis=1)[0]
    
    # Get the class label and confidence
    predicted_class_label = class_labels[predicted_class_idx]
    confidence = predictions[0][predicted_class_idx]
    
    return predicted_class_label, confidence

# Example usage
image_path = "train\Very mild Dementia\OAS1_0003_MR1_mpr-1_103.jpg"  # Replace with your test image path
predicted_class_label, confidence = predict_class(image_path)

print(f"Predicted Class: {predicted_class_label}")


import tensorflow as tf
from tensorflow.keras.preprocessing import image
import numpy as np

# Define class labels based on your training
class_labels = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']

# Load the saved model
model = tf.keras.models.load_model("mobilenet_model.h5")

# Function to preprocess image and make prediction
def predict_class(image_path):
    # Load the image, resize it to 224x224 (the target size used in training)
    img = image.load_img(image_path, target_size=(224, 224), color_mode='grayscale')
    
    # Convert the image to a numpy array and expand dimensions (for batch size of 1)
    img_array = image.img_to_array(img)  # Convert image to numpy array
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    
    # Normalize the image
    img_array /= 255.0  # Same normalization as during training
    
    # Predict using the model
    predictions = model.predict(img_array)
    
    # Get the class index with the highest probability
    predicted_class_idx = np.argmax(predictions, axis=1)[0]
    
    # Get the class label and confidence
    predicted_class_label = class_labels[predicted_class_idx]
    confidence = predictions[0][predicted_class_idx]
    
    return predicted_class_label, confidence

# Example usage
image_path = "test\Very mild Dementia\OAS1_0003_MR1_mpr-1_144.jpg"  # Replace with your test image path
predicted_class_label, confidence = predict_class(image_path)

print(f"Predicted Class: {predicted_class_label}")
## ResNet Model
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import os
# Load and preprocess the data
train_dir = "train"
val_dir = "test"
# Data augmentation for training set
datagen_train = ImageDataGenerator(rescale=1.0/255, rotation_range=30, width_shift_range=0.2, 
                                   height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, 
                                   horizontal_flip=True, fill_mode='nearest')

datagen_val = ImageDataGenerator(rescale=1.0/255)

train_data = datagen_train.flow_from_directory(train_dir, target_size=(224, 224), batch_size=16, 
                                               class_mode='categorical', color_mode='grayscale')
val_data = datagen_val.flow_from_directory(val_dir, target_size=(224, 224), batch_size=16, 
                                           class_mode='categorical', color_mode='grayscale', shuffle=False)


# Load the ResNet50 model
base_model = ResNet50(input_shape=(224, 224, 3), include_top=False, weights='imagenet')
base_model.trainable = False

# Adjust the input for grayscale images by adding a Conv2D layer to expand channel to 3
input_layer = tf.keras.layers.Input(shape=(224, 224, 1))
x = tf.keras.layers.Conv2D(3, (3, 3), padding='same', activation='relu')(input_layer)
x = base_model(x, training=False)

# Build the rest of the model
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(128, activation='relu')(x)
x = tf.keras.layers.Dropout(0.5)(x)
output_layer = tf.keras.layers.Dense(4, activation='softmax')(x)

model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
epochs = 30
history = model.fit(train_data, validation_data=val_data, epochs=epochs)

# Save the model
model.save("brain_tumor_resnet50_mri_model.h5")

# Plot accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training and Validation Accuracy')
plt.show()

# Evaluate the model and plot confusion matrix
y_pred = model.predict(val_data)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = val_data.classes
# Confusion Matrix
conf_mat = confusion_matrix(y_true, y_pred_classes)
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()
# Classification Report
print("Classification Report:\n")
print(classification_report(y_true, y_pred_classes))
